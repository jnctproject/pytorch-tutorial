{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNduzFKfoNS82P8pofLdHCw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnctproject/pytorch-tutorial/blob/main/cnn_model_for_pressure_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0hi7-YZXW2Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define file paths\n",
        "file_paths = [\n",
        "\n",
        "    \"G:/Mahendra Singh Sisodia/m1data.dat\",\n",
        "\n",
        "]\n",
        "\n",
        "# Data processing\n",
        "images, labels = [], []\n",
        "coordinates, pressures = [], []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    df = pd.read_csv(file_path, delimiter='\\s+', header=0)\n",
        "    x_values = np.sort(df['x-coordinate'].unique())[::-1]\n",
        "\n",
        "    for x1 in x_values:\n",
        "        # Increased tolerance to 1e-3 and added check for finite values:\n",
        "        mask = np.isclose(df['x-coordinate'], x1, atol=1e-3) & np.isfinite(df['x-coordinate'])\n",
        "\n",
        "        # Check if mask is empty:\n",
        "        if not mask.any():\n",
        "            print(f\"Warning: No data points found for x-coordinate: {x1}, skipping...\")\n",
        "            continue  # Skip to the next iteration if mask is empty\n",
        "\n",
        "        y, z, pressure = df.loc[mask, 'y-coordinate'], df.loc[mask, 'z-coordinate'], df.loc[mask, 'pressure']\n",
        "\n",
        "        coordinates.append((x1, y.values, z.values))\n",
        "        pressures.append(pressure.values)\n",
        "\n",
        "        y_unique = np.linspace(y.min(), y.max(), 300)\n",
        "        z_unique = np.linspace(z.min(), z.max(), 300)\n",
        "        Y, Z = np.meshgrid(y_unique, z_unique)\n",
        "\n",
        "        pressure_grid = griddata((y, z), pressure, (Y, Z), method='cubic')\n",
        "        if np.isnan(pressure_grid).sum() > 0:\n",
        "            pressure_grid = griddata((y, z), pressure, (Y, Z), method='nearest')\n",
        "\n",
        "        pressure_grid = (pressure_grid - np.min(pressure_grid)) / (np.max(pressure_grid) - np.min(pressure_grid))\n",
        "        image = pressure_grid.reshape((1, 300, 300))\n",
        "\n",
        "        images.append(image)\n",
        "        labels.append(x1)\n",
        "\n",
        "X_data = torch.tensor(np.array(images), dtype=torch.float32)\n",
        "y_data = torch.tensor(np.array(labels), dtype=torch.float32)\n",
        "y_min, y_max = y_data.min(), y_data.max()\n",
        "y_data = (y_data - y_min) / (y_max - y_min)\n",
        "\n",
        "# Define Dataset class\n",
        "class PressureDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "dataset = PressureDataset(X_data, y_data)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 18 * 18, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "model = CNNModel().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch).squeeze()\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate model\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        preds = model(X_batch).squeeze()\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "# Convert predictions back to original scale\n",
        "all_preds = np.array(all_preds) * (y_max.cpu().numpy() - y_min.cpu().numpy()) + y_min.cpu().numpy()\n",
        "all_labels = np.array(all_labels) * (y_max.cpu().numpy() - y_min.cpu().numpy()) + y_min.cpu().numpy()\n",
        "print(\"Predictions:\", all_preds[:10])\n",
        "print(\"Actual:\", all_labels[:10])\n",
        "\n",
        "# Assign y_test (Assuming all_labels represents the test labels)\n",
        "y_test = torch.tensor(all_labels) # Convert to tensor if required\n",
        "\n",
        "# Plot Predicted Pressure Contours\n",
        "x_values = np.linspace(-3, 30, 10)\n",
        "for x_pred in x_values:\n",
        "    closest_index = np.argmin([abs(x1 - x_pred) for x1, _, _ in coordinates])\n",
        "    _, y_vals, z_vals = coordinates[closest_index]\n",
        "    pressure_vals = pressures[closest_index]\n",
        "\n",
        "    y_grid = np.linspace(min(y_vals), max(y_vals), 300)\n",
        "    z_grid = np.linspace(min(z_vals), max(z_vals), 300)\n",
        "    Y_grid, Z_grid = np.meshgrid(y_grid, z_grid)\n",
        "\n",
        "    pressure_interp = griddata((y_vals, z_vals), pressure_vals, (Y_grid, Z_grid), method='cubic')\n",
        "    if np.isnan(pressure_interp).sum() > 0:\n",
        "        pressure_interp = griddata((y_vals, z_vals), pressure_vals, (Y_grid, Z_grid), method='nearest')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.contourf(Y_grid, Z_grid, pressure_interp, levels=100, cmap='jet')\n",
        "    plt.colorbar(label='Predicted Pressure')\n",
        "    plt.xlabel('Y-coordinate')\n",
        "    plt.ylabel('Z-coordinate')\n",
        "    plt.title(f'Predicted Pressure Contour at X = {x_pred:.2f}')\n",
        "    plt.show()\n"
      ]
    }
  ]
}